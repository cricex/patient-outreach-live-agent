{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd62f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env.notebook\n",
    "# This allows you to keep your notebook-specific secrets and configurations separate\n",
    "# from your main application's .env file.\n",
    "if os.path.exists(\"../.env.notebook\"):\n",
    "    load_dotenv(dotenv_path=\"../.env.notebook\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d2b119",
   "metadata": {},
   "source": [
    "### Overview\n",
    "This notebook orchestrates a two-stage AI workflow:\n",
    "1. Review each patient's clinical JSON to decide if preventive outreach is needed and (if so) generate a structured `CALL_BRIEF`.\n",
    "2. Generate a concise, natural phone message from a selected `CALL_BRIEF`, then optionally place an outbound call via Azure Communication Services.\n",
    "\n",
    "The next cell only contains (commented) optional install commands for dependencies; it's intentionally lightweight so environments that already have packages aren't slowed down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c72dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If your environment doesn't have these already, uncomment:\n",
    "#!pip install --quiet --upgrade openai pandas\n",
    "#!pip install --upgrade \"azure-communication-callautomation>=1.2.0\"\n",
    "#!pip install --quiet azure-communication-callautomation fastapi uvicorn nest_asyncio pyngrok\n",
    "\n",
    "#import pkg_resources\n",
    "#print(\"callautomation version:\", pkg_resources.get_distribution(\"azure-communication-callautomation\").version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4feb6c6",
   "metadata": {},
   "source": [
    "### Imports, Environment, and Configuration\n",
    "The next cell:\n",
    "- Imports core libraries (`os`, `json`, `re`, `pandas`, path utilities, typing helpers).\n",
    "- Loads required environment variables for Azure OpenAI + Azure Communication Services + TTS.\n",
    "- Prints a quick readiness report (which secrets are set) to help validate runtime config before any API calls.\n",
    "No external network calls happen yet—it's pure setup / validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221bde12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, re\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Env vars (set these in your environment or just override here)\n",
    "\n",
    "NOTES_PATH = os.getenv(\"NOTES_PATH\", \"./clinical_notes\")  # folder with .json files\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\", \"\")\n",
    "AZURE_OPENAI_KEY = os.getenv(\"AI_FOUNDRY_API_KEY\", \"\")\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\", \"\")\n",
    "AZURE_OPENAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2024-02-15-preview\")\n",
    "\n",
    "TARGET_PHONE_NUMBER = os.getenv(\"TARGET_PHONE_NUMBER\", \"\")\n",
    "ACS_CONNECTION_STRING = os.getenv(\"ACS_CONNECTION_STRING\", \"\")\n",
    "ACS_PHONE_NUMBER = os.getenv(\"ACS_OUTBOUND_CALLER_ID\", \"\")\n",
    "\n",
    "APP_BASE_URL = os.getenv(\"APP_BASE_URL\", \"http://localhost:8000\")\n",
    "TTS_VOICE = os.getenv(\"TTS_VOICE\", \"en-US-AvaMultilingualNeural\")\n",
    "COGNITIVE_SERVICES_ENDPOINT = os.getenv(\"COGNITIVE_SERVICES_ENDPOINT\", \"\")\n",
    "\n",
    "print(\"NOTES_PATH:\", NOTES_PATH)\n",
    "print(\"AZURE_OPENAI_ENDPOINT set:\", bool(AZURE_OPENAI_ENDPOINT))\n",
    "print(\"AZURE_OPENAI_KEY set:\", bool(AZURE_OPENAI_KEY))\n",
    "print(\"AZURE_OPENAI_DEPLOYMENT_NAME:\", AZURE_OPENAI_DEPLOYMENT_NAME or \"(not set)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e879b91a",
   "metadata": {},
   "source": [
    "### Azure OpenAI Client Initialization\n",
    "Creates the Azure OpenAI client using environment variables. This is the only place credentials are bound.\n",
    "Fail-fast validation ensures misconfiguration is caught *before* iterating any patient files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025ca7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Azure OpenAI client\n",
    "\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "if not AZURE_OPENAI_ENDPOINT or not AZURE_OPENAI_KEY or not AZURE_OPENAI_DEPLOYMENT_NAME:\n",
    "    raise RuntimeError(\"Please set AZURE_OPENAI_ENDPOINT, AZURE_OPENAI_KEY, and AZURE_OPENAI_DEPLOYMENT_NAME.\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=AZURE_OPENAI_KEY,\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_version=AZURE_OPENAI_API_VERSION  # update if your resource uses a different version\n",
    ")\n",
    "print(\"Azure OpenAI client initialized.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ee02c2",
   "metadata": {},
   "source": [
    "### Primary SYSTEM_PROMPT Definition\n",
    "Defines the instruction block for the FIRST model call. Responsibilities:\n",
    "- Analyze a single patient's clinical JSON.\n",
    "- Decide if an appointment is needed (`appointment_needed`).\n",
    "- If needed, emit a richly structured multi-line `CALL_BRIEF` string wrapped between BEGIN/END markers.\n",
    "The strict JSON envelope keeps downstream parsing trivial and minimizes payload size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95fdf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = r\"\"\"\n",
    "You are an AI health agent that reviews patient history in JSON format.\n",
    "Your tasks are:\n",
    "1) Evaluate preventive care needs based on the patient's history.\n",
    "2) If an appointment is needed, generate a detailed call brief for a voice agent.\n",
    "\n",
    "Input: You will receive ONE JSON object with patient clinical notes.\n",
    "\n",
    "Output: ALWAYS return JSON in this exact shape:\n",
    "{\n",
    "  \"patient_id\": \"string\",\n",
    "  \"appointment_needed\": true,\n",
    "  \"call_brief\": \"BEGIN CALL_BRIEF\\nNAME: Jane\\nAGE: 62\\nAGE_BUCKET_SPOKEN: in your sixties\\nSEX: female\\nPRONOUNS: she/her\\n\\nMULTI_NEED: true\\nTOP_NEED: colonoscopy\\n\\nNEEDS:\\n- AREA: colonoscopy\\n  PRIORITY: high\\n  TIMING: in the next one to three months\\n  WHY_SHORT: Last colonoscopy was back in October 2013; the ten-year repeat is overdue.\\n  HISTORY_SPOKEN: Screening colonoscopy in October 2013; no colonoscopy documented as of March 2021\\n  OVERDUE_FLAG: true\\n\\n- AREA: mammogram\\n  PRIORITY: routine\\n  TIMING: by August 2024\\n  WHY_SHORT: No mammogram in the past two years; recommended every one to two years from forty to seventy-four.\\n  HISTORY_SPOKEN: No recent mammogram noted as of March 2021\\n  OVERDUE_FLAG: true\\n\\nINTENT_CLUES: schedule|set up|book|dates|times\\nSCHED_WINDOW_PREF: this week or next two weeks\\nEND CALL_BRIEF\"\n",
    "}\n",
    "\n",
    "Rules:\n",
    "- Be concise and clinically relevant.\n",
    "- Do not invent data not present in notes.\n",
    "- If unknown/missing, use \"not_documented\" or null for string values.\n",
    "- If nothing is due, return \"appointment_needed\": false and \"call_brief\": null.\n",
    "- The `call_brief` field must be a string containing the full brief as shown in the example, or null.\n",
    "- The `patient_id` should be extracted from the input JSON.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26be156f",
   "metadata": {},
   "source": [
    "### Minimal Helper Utilities\n",
    "Utility functions only:\n",
    "- `load_json_files` enumerates patient JSON files.\n",
    "- `read_json` loads one file.\n",
    "- `try_extract_json` robustly recovers a JSON object from the model output (direct, fenced code block, or best-effort brace scan) to reduce prompt brittleness.\n",
    "These are intentionally lean—previous heavier helpers were removed to streamline the path from raw file to structured result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41599b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for loading/validating notes and parsing model output\n",
    "\n",
    "def load_json_files(notes_path: str) -> List[Path]:\n",
    "    p = Path(notes_path)\n",
    "    if not p.exists() or not p.is_dir():\n",
    "        raise FileNotFoundError(f\"NOTES_PATH does not exist or is not a directory: {notes_path}\")\n",
    "    return sorted([f for f in p.iterdir() if f.suffix.lower() == \".json\"])\n",
    "\n",
    "def read_json(path: Path) -> Any:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def try_extract_json(text: str) -> Optional[dict]:\n",
    "    \"\"\"Try to parse JSON from model output: direct, fenced code, or brace scan.\"\"\"\n",
    "    # direct\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # fenced ```json ... ```\n",
    "    fence = re.search(r\"```(?:json)?\\s*(\\{.*?\\})\\s*```\", text, flags=re.S|re.I)\n",
    "    if fence:\n",
    "        try:\n",
    "            return json.loads(fence.group(1))\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # coarse brace matching\n",
    "    start, end = text.find(\"{\"), text.rfind(\"}\")\n",
    "    if start != -1 and end != -1 and end > start:\n",
    "        candidate = text[start:end+1]\n",
    "        for j in range(len(candidate), 1, -1):\n",
    "            snippet = candidate[:j]\n",
    "            try:\n",
    "                return json.loads(snippet)\n",
    "            except Exception:\n",
    "                continue\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1fa7c0",
   "metadata": {},
   "source": [
    "### First-Stage Inference Loop\n",
    "Workflow per patient file:\n",
    "1. Load raw JSON.\n",
    "2. Send to model with `SYSTEM_PROMPT`.\n",
    "3. Attempt robust JSON extraction.\n",
    "4. Append a normalized result record (never crashes the loop on single-file failure).\n",
    "Design choices:\n",
    "- Temperature 0 for determinism.\n",
    "- Graceful fallback object on parse errors.\n",
    "- Minimal fields retained to keep memory + downstream logic small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a011091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each JSON\n",
    "\n",
    "files = load_json_files(NOTES_PATH)\n",
    "print(f\"Found {len(files)} JSON file(s) in {NOTES_PATH}.\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, path in enumerate(files, start=1):\n",
    "    try:\n",
    "        print(f\"\\n[{i}/{len(files)}] Processing: {path.name}\")\n",
    "        # Simplified: read the json file directly.\n",
    "        patient_obj = read_json(path)\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": json.dumps(patient_obj, ensure_ascii=False)}\n",
    "        ]\n",
    "\n",
    "        resp = client.chat.completions.create(\n",
    "            model=AZURE_OPENAI_DEPLOYMENT_NAME,  # your *deployment* name\n",
    "            messages=messages,\n",
    "            temperature=0\n",
    "        )\n",
    "        content = resp.choices[0].message.content\n",
    "\n",
    "        parsed = try_extract_json(content)\n",
    "        if not parsed:\n",
    "            # If parsing fails, create a minimal error object\n",
    "            parsed = {\n",
    "                \"patient_id\": path.stem, # Use filename stem as a fallback patient_id\n",
    "                \"appointment_needed\": False,\n",
    "                \"call_brief\": None,\n",
    "                \"error\": \"Model response was not valid JSON\",\n",
    "                \"raw\": content\n",
    "            }\n",
    "\n",
    "        # The new structure is simpler, so we just append the parsed object\n",
    "        # along with the source filename.\n",
    "        results.append({\n",
    "            \"file\": path.name,\n",
    "            \"patient_id\": parsed.get(\"patient_id\", path.stem),\n",
    "            \"appointment_needed\": bool(parsed.get(\"appointment_needed\", False)),\n",
    "            \"call_brief\": parsed.get(\"call_brief\"),\n",
    "            \"error\": parsed.get(\"error\") # Carry over any errors\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        results.append({\n",
    "            \"file\": path.name,\n",
    "            \"patient_id\": \"(unknown)\",\n",
    "            \"appointment_needed\": False,\n",
    "            \"call_brief\": None,\n",
    "            \"error\": str(e)\n",
    "        })\n",
    "\n",
    "print(\"\\nCompleted.\")\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdbe7d0",
   "metadata": {},
   "source": [
    "### Display Raw Call Briefs (Diagnostic)\n",
    "Iterates accumulated results and prints each `CALL_BRIEF` only for patients flagged `appointment_needed`.\n",
    "Useful for:\n",
    "- Quick qualitative spot checks of prompt adherence.\n",
    "- Ensuring parse fallbacks didn't silently mask issues.\n",
    "This is a human-facing inspection step—safe to skip in automation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077dbcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the call brief for each patient needing an appointment\n",
    "for r in results:\n",
    "    if r.get(\"appointment_needed\"):\n",
    "        print(f\"--- CALL BRIEF for Patient: {r.get('patient_id', 'Unknown')} ---\")\n",
    "        if r.get(\"call_brief\"):\n",
    "            print(r['call_brief'])\n",
    "        else:\n",
    "            print(\"(No call brief generated)\")\n",
    "        print(\"-\" * 50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a006b7d",
   "metadata": {},
   "source": [
    "### Build & Sort Results DataFrame\n",
    "Converts the in-memory list of dicts to a tidy DataFrame restricted to the minimal analytic columns.\n",
    "Sorting brings patients needing outreach to the top for convenient browsing.\n",
    "This becomes the canonical structured artifact feeding the second model stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24662e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Keep only relevant columns\n",
    "df = df[[\"file\", \"patient_id\", \"appointment_needed\", \"call_brief\", \"error\"]]\n",
    "\n",
    "df.sort_values(by=[\"appointment_needed\", \"patient_id\"], ascending=[False, True], inplace=True, kind=\"stable\")\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd11f358",
   "metadata": {},
   "source": [
    "### Second-Stage CALL_SYSTEM_PROMPT\n",
    "This prompt transforms a single `CALL_BRIEF` into a patient-facing outbound phone message:\n",
    "- Enforces tone, length, safety, and formatting (plain text only).\n",
    "- Treats multi-need vs single-need differently for wording.\n",
    "It's deliberately concise to reduce token footprint while constraining style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e776d704",
   "metadata": {},
   "outputs": [],
   "source": [
    "CALL_SYSTEM_PROMPT = r\"\"\"\n",
    "You generate one concise, conversational phone message asking a patient to make a MyChart appointment.\n",
    "\n",
    "Input: A CALL_BRIEF string with patient details and health needs.\n",
    "\n",
    "Output: Only the raw text message, no JSON, no extra formatting.\n",
    "\n",
    "Rules:\n",
    "- Always include the patient’s first name (from the NAME field) in the salutation.\n",
    "- Begin the message as if it’s coming from an assistant at the Microsoft Health Clinic.\n",
    "- Tone: conversational and friendly.\n",
    "- Reason: If MULTI_NEED is false, you can mention the TOP_NEED. If MULTI_NEED is true, keep it generic (\"preventive care\" or \"health needs\").\n",
    "- Length: 15–35 words, max 220 characters, 1–2 sentences.\n",
    "- Keep language natural, simple, and easy to speak aloud.\n",
    "- No sensitive details beyond the first name and one preventive item (if included).\n",
    "- Close with a friendly nudge to confirm or schedule soon.\n",
    "- Do not include clinic phone numbers or links (these are added later by the dialer).\n",
    "\n",
    "Example Input:\n",
    "BEGIN CALL_BRIEF\n",
    "NAME: Robert\n",
    "...\n",
    "TOP_NEED: colonoscopy\n",
    "MULTI_NEED: false\n",
    "...\n",
    "END CALL_BRIEF\n",
    "\n",
    "→ Example Output:\n",
    "Hey Robert, it’s us again from the Microsoft Health Clinic. We noticed it’s been a while since your screening colonoscopy — would you like to set up an appointment soon?\n",
    "\n",
    "Example Input:\n",
    "BEGIN CALL_BRIEF\n",
    "NAME: Sarah\n",
    "...\n",
    "TOP_NEED: colonoscopy\n",
    "MULTI_NEED: true\n",
    "...\n",
    "END CALL_BRIEF\n",
    "\n",
    "→ Example Output:\n",
    "Hi Sarah, this is the Microsoft Health Clinic. It looks like you may be due for your preventive care. Would you like to schedule a visit with us?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c867063b",
   "metadata": {},
   "source": [
    "### Select Target Patient & Assemble Second Call Messages\n",
    "Filters only patients needing outreach, selects the second one (demo logic), and constructs the chat message list (`call_prompt`) for the second model call.\n",
    "If insufficient patients qualify, it safely aborts by leaving `call_prompt` empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fef38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare call prompt for the second patient in the dataframe\n",
    "\n",
    "# Filter for patients who need an appointment\n",
    "outreach_df = df[df[\"appointment_needed\"] == True].copy()\n",
    "\n",
    "if len(outreach_df) > 1:\n",
    "    # Get the call_brief from the second patient in the filtered dataframe\n",
    "    call_brief_string = outreach_df.iloc[1][\"call_brief\"]\n",
    "\n",
    "    call_prompt = [\n",
    "        {\"role\": \"system\", \"content\": CALL_SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": call_brief_string}\n",
    "    ]\n",
    "\n",
    "    print(\"--- Using Call Brief for Prompt ---\")\n",
    "    print(call_brief_string)\n",
    "else:\n",
    "    print(\"Not enough patients needing an appointment to select the second one.\")\n",
    "    call_prompt = [] # Ensure call_prompt is empty so the next cell doesn't run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4d1952",
   "metadata": {},
   "source": [
    "### Generate Outbound Call Message Text\n",
    "Executes the second model call using the prepared `call_prompt` to obtain a final, human-spoken style message.\n",
    "Output is plain text only—ready for text-to-speech and dialing in subsequent steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fe6c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the call message to Azure OpenAI\n",
    "\n",
    "resp = client.chat.completions.create(\n",
    "    model=AZURE_OPENAI_DEPLOYMENT_NAME,  # your *deployment* name\n",
    "    messages=call_prompt,\n",
    "    temperature=0\n",
    ")\n",
    "call_message = resp.choices[0].message.content\n",
    "\n",
    "print(call_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a570da",
   "metadata": {},
   "source": [
    "## Make Phone Call ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dfb632",
   "metadata": {},
   "source": [
    "### Place Phone Call via Azure Communication Services\n",
    "The next code cell dials the target number using ACS, waits for connection, plays the synthesized message using the configured neural voice, then hangs up after a short dwell window.\n",
    "Includes a timeout guard and conservative sleep logic to avoid premature hang-up.\n",
    "\n",
    "> **Demo Only (One‑Way Playback):** This cell places a simple outbound call and plays the generated `call_message`. \n",
    "> It does not listen for speech/DTMF, gather patient input, or branch logic. \n",
    "> For the interactive / production workflow (turn-taking, state, routing), see `main.py`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ede0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from azure.communication.callautomation import (\n",
    "    CallAutomationClient,\n",
    "    PhoneNumberIdentifier,\n",
    "    TextSource,\n",
    "    CallConnectionState,\n",
    ")\n",
    "\n",
    "\n",
    "def call_and_say(message: str) -> None:\n",
    "    acs = CallAutomationClient.from_connection_string(ACS_CONNECTION_STRING)\n",
    "\n",
    "    create_result = acs.create_call(\n",
    "        target_participant=PhoneNumberIdentifier(TARGET_PHONE_NUMBER),   # E.164 format\n",
    "        callback_url=APP_BASE_URL,                                       # must be publicly reachable HTTPS\n",
    "        source_caller_id_number=PhoneNumberIdentifier(ACS_PHONE_NUMBER), # caller ID shown to callee\n",
    "        #cognitive_services_endpoint=os.environ[\"COGNITIVE_SERVICES_ENDPOINT\"],\n",
    "        cognitive_services_endpoint=COGNITIVE_SERVICES_ENDPOINT\n",
    "    )\n",
    "\n",
    "    call_conn = acs.get_call_connection(create_result.call_connection_id)\n",
    "\n",
    "    # Wait briefly for the call to connect before playing media\n",
    "    deadline = time.time() + 30\n",
    "    while time.time() < deadline:\n",
    "        state = call_conn.get_call_properties().call_connection_state\n",
    "        if state == CallConnectionState.CONNECTED or str(state).lower() == \"connected\":\n",
    "            break\n",
    "        time.sleep(0.5)\n",
    "    else:\n",
    "        raise TimeoutError(\"Call did not connect within 30 seconds.\")\n",
    "\n",
    "    # Speak the message using your chosen voice\n",
    "    tts_voice = TTS_VOICE\n",
    "    text_source = TextSource(text=message, voice_name=tts_voice)\n",
    "    call_conn.play_media_to_all(text_source)\n",
    "\n",
    "    # Optional: hang up after a short delay\n",
    "    time.sleep(min(15, max(5, len(message) / 10)))\n",
    "    call_conn.hang_up(is_for_everyone=True)\n",
    "\n",
    "call_and_say(call_message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
